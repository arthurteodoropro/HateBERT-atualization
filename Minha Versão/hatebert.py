# -*- coding: utf-8 -*-
"""HateBERT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DKM8JndESOZORlUPNoYtU-bKD-wL-DVq
"""

# Commented out IPython magic to ensure Python compatibility.
# ========================================
# BAIXAR DIRETO DO OSF PARA O COLAB
# ========================================

# %cd /content

print("üì• Baixando projeto HateBERT do OSF...")
!pip install -q osfclient

print("\nüìÇ Clonando projeto tbd58 do OSF...")
!osf -p tbd58 clone HateBERT_Project

print("\n‚úÖ Download conclu√≠do!")

print("\nüìã Estrutura baixada:")
!ls -lah HateBERT_Project/

print("\nüìÇ Conte√∫do de osfstorage:")
!ls -lah HateBERT_Project/osfstorage/

print("\nüìÇ Software:")
!ls -lah HateBERT_Project/osfstorage/software/

print("\n‚úÖ Pronto para treinar!")

# Commented out IPython magic to ensure Python compatibility.
# ========================================
# TREINAR COM 5 √âPOCAS + GR√ÅFICOS DE APRENDIZAGEM
# ========================================

# %cd /content/HateBERT_Project/osfstorage

print("üì¶ Instalando depend√™ncias...")
!pip install -q transformers datasets torch scikit-learn pandas numpy tqdm matplotlib seaborn

print("\n‚öôÔ∏è Criando script de treinamento com 5 √©pocas e gr√°ficos...")

with open('train_5epochs_graphs.py', 'w') as f:
    f.write('import torch\n')
    f.write('from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n')
    f.write('from datasets import load_dataset\n')
    f.write('import numpy as np\n')
    f.write('from sklearn.metrics import accuracy_score, precision_recall_fscore_support, f1_score, confusion_matrix\n')
    f.write('import matplotlib.pyplot as plt\n')
    f.write('import seaborn as sns\n')
    f.write('import json\n')
    f.write('import os\n\n')

    f.write('print("üîß Configurando treinamento HateBERT com 5 √©pocas...")\n\n')

    f.write('MODEL_NAME = "GroNLP/hateBERT"\n')
    f.write('OUTPUT_DIR = "./hatebert_5epochs"\n')
    f.write('NUM_EPOCHS = 5\n')
    f.write('BATCH_SIZE = 16\n\n')

    f.write('device = "cuda" if torch.cuda.is_available() else "cpu"\n')
    f.write('print(f"üíª Usando: {device}")\n\n')

    f.write('print("\\nüì• Carregando HateBERT...")\n')
    f.write('tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n')
    f.write('model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2)\n\n')

    f.write('print("\\nüìä Carregando dataset de hate speech (tweet_eval)...")\n')
    f.write('dataset = load_dataset("tweet_eval", "hate")\n\n')

    f.write('print(f"Dados de treino: {len(dataset[\'train\'])} exemplos")\n')
    f.write('print(f"Dados de valida√ß√£o: {len(dataset[\'validation\'])} exemplos")\n')
    f.write('print(f"Dados de teste: {len(dataset[\'test\'])} exemplos")\n\n')

    f.write('def tokenize_function(examples):\n')
    f.write('    return tokenizer(examples["text"], padding="max_length", truncation=True, max_length=128)\n\n')

    f.write('print("\\nüîÑ Tokenizando dados...")\n')
    f.write('tokenized_datasets = dataset.map(tokenize_function, batched=True)\n\n')

    f.write('def compute_metrics(eval_pred):\n')
    f.write('    logits, labels = eval_pred\n')
    f.write('    predictions = np.argmax(logits, axis=-1)\n')
    f.write('    acc = accuracy_score(labels, predictions)\n')
    f.write('    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average="binary")\n')
    f.write('    return {\n')
    f.write('        "accuracy": acc,\n')
    f.write('        "f1": f1,\n')
    f.write('        "precision": precision,\n')
    f.write('        "recall": recall\n')
    f.write('    }\n\n')

    f.write('print("\\n‚öôÔ∏è Configurando treinamento com 5 √©pocas...")\n')
    f.write('training_args = TrainingArguments(\n')
    f.write('    output_dir=OUTPUT_DIR,\n')
    f.write('    num_train_epochs=NUM_EPOCHS,\n')
    f.write('    per_device_train_batch_size=BATCH_SIZE,\n')
    f.write('    per_device_eval_batch_size=32,\n')
    f.write('    learning_rate=2e-5,\n')
    f.write('    warmup_steps=500,\n')
    f.write('    weight_decay=0.01,\n')
    f.write('    logging_dir="./logs",\n')
    f.write('    logging_steps=50,\n')
    f.write('    eval_strategy="epoch",\n')
    f.write('    save_strategy="epoch",\n')
    f.write('    load_best_model_at_end=True,\n')
    f.write('    metric_for_best_model="f1",\n')
    f.write('    save_total_limit=2,\n')
    f.write('    report_to="none",\n')
    f.write('    fp16=torch.cuda.is_available(),\n')
    f.write(')\n\n')

    f.write('trainer = Trainer(\n')
    f.write('    model=model,\n')
    f.write('    args=training_args,\n')
    f.write('    train_dataset=tokenized_datasets["train"],\n')
    f.write('    eval_dataset=tokenized_datasets["validation"],\n')
    f.write('    tokenizer=tokenizer,\n')
    f.write('    compute_metrics=compute_metrics,\n')
    f.write(')\n\n')

    f.write('print("\\nüöÄ Iniciando treinamento com 5 √©pocas...")\n')
    f.write('print("‚è±Ô∏è Estimativa com GPU: ~12-20 minutos\\n")\n\n')

    f.write('train_result = trainer.train()\n\n')

    f.write('print("\\nüìä Avaliando no conjunto de teste...")\n')
    f.write('test_results = trainer.evaluate(tokenized_datasets["test"])\n')
    f.write('print(f"\\n‚úÖ M√©tricas no teste:")\n')
    f.write('print(f"   Accuracy:  {test_results[\'eval_accuracy\']:.4f}")\n')
    f.write('print(f"   F1-Score:  {test_results[\'eval_f1\']:.4f}")\n')
    f.write('print(f"   Precision: {test_results[\'eval_precision\']:.4f}")\n')
    f.write('print(f"   Recall:    {test_results[\'eval_recall\']:.4f}")\n\n')

    f.write('# Salvar modelo\n')
    f.write('print(f"\\nüíæ Salvando modelo em {OUTPUT_DIR}...")\n')
    f.write('trainer.save_model(OUTPUT_DIR)\n')
    f.write('tokenizer.save_pretrained(OUTPUT_DIR)\n\n')

    f.write('# ========================================\n')
    f.write('# GERAR GR√ÅFICOS DE APRENDIZAGEM\n')
    f.write('# ========================================\n\n')

    f.write('print("\\nüìà Gerando gr√°ficos de aprendizagem...")\n\n')

    f.write('# Extrair hist√≥rico de treinamento\n')
    f.write('history = trainer.state.log_history\n\n')

    f.write('# Separar m√©tricas de treino e valida√ß√£o\n')
    f.write('train_loss = []\n')
    f.write('eval_loss = []\n')
    f.write('eval_accuracy = []\n')
    f.write('eval_f1 = []\n')
    f.write('eval_precision = []\n')
    f.write('eval_recall = []\n')
    f.write('epochs = []\n\n')

    f.write('for entry in history:\n')
    f.write('    if "loss" in entry and "epoch" in entry:\n')
    f.write('        train_loss.append(entry["loss"])\n')
    f.write('    if "eval_loss" in entry:\n')
    f.write('        eval_loss.append(entry["eval_loss"])\n')
    f.write('        eval_accuracy.append(entry["eval_accuracy"])\n')
    f.write('        eval_f1.append(entry["eval_f1"])\n')
    f.write('        eval_precision.append(entry["eval_precision"])\n')
    f.write('        eval_recall.append(entry["eval_recall"])\n')
    f.write('        epochs.append(entry["epoch"])\n\n')

    f.write('# Criar diret√≥rio para gr√°ficos\n')
    f.write('os.makedirs("./graphs", exist_ok=True)\n\n')

    f.write('# Configurar estilo dos gr√°ficos\n')
    f.write('plt.style.use("seaborn-v0_8-darkgrid")\n')
    f.write('sns.set_palette("husl")\n\n')

    f.write('# GR√ÅFICO 1: Loss durante o treinamento\n')
    f.write('fig, ax = plt.subplots(figsize=(10, 6))\n')
    f.write('if eval_loss:\n')
    f.write('    ax.plot(epochs, eval_loss, marker="o", linewidth=2, markersize=8, label="Validation Loss")\n')
    f.write('ax.set_xlabel("√âpoca", fontsize=12, fontweight="bold")\n')
    f.write('ax.set_ylabel("Loss", fontsize=12, fontweight="bold")\n')
    f.write('ax.set_title("Perda durante o Treinamento (5 √âpocas)", fontsize=14, fontweight="bold")\n')
    f.write('ax.legend(fontsize=10)\n')
    f.write('ax.grid(True, alpha=0.3)\n')
    f.write('plt.tight_layout()\n')
    f.write('plt.savefig("./graphs/loss_curve.png", dpi=300, bbox_inches="tight")\n')
    f.write('plt.show()\n')
    f.write('print("‚úÖ Gr√°fico exibido e salvo: ./graphs/loss_curve.png")\n\n')

    f.write('# GR√ÅFICO 2: Accuracy\n')
    f.write('fig, ax = plt.subplots(figsize=(10, 6))\n')
    f.write('ax.plot(epochs, eval_accuracy, marker="o", linewidth=2, markersize=8, color="green", label="Validation Accuracy")\n')
    f.write('ax.set_xlabel("√âpoca", fontsize=12, fontweight="bold")\n')
    f.write('ax.set_ylabel("Accuracy", fontsize=12, fontweight="bold")\n')
    f.write('ax.set_title("Acur√°cia durante o Treinamento (5 √âpocas)", fontsize=14, fontweight="bold")\n')
    f.write('ax.set_ylim([0, 1])\n')
    f.write('ax.legend(fontsize=10)\n')
    f.write('ax.grid(True, alpha=0.3)\n')
    f.write('plt.tight_layout()\n')
    f.write('plt.savefig("./graphs/accuracy_curve.png", dpi=300, bbox_inches="tight")\n')
    f.write('plt.show()\n')
    f.write('print("‚úÖ Gr√°fico exibido e salvo: ./graphs/accuracy_curve.png")\n\n')

    f.write('# GR√ÅFICO 3: F1, Precision e Recall\n')
    f.write('fig, ax = plt.subplots(figsize=(12, 6))\n')
    f.write('ax.plot(epochs, eval_f1, marker="o", linewidth=2, markersize=8, label="F1-Score")\n')
    f.write('ax.plot(epochs, eval_precision, marker="s", linewidth=2, markersize=8, label="Precision")\n')
    f.write('ax.plot(epochs, eval_recall, marker="^", linewidth=2, markersize=8, label="Recall")\n')
    f.write('ax.set_xlabel("√âpoca", fontsize=12, fontweight="bold")\n')
    f.write('ax.set_ylabel("Score", fontsize=12, fontweight="bold")\n')
    f.write('ax.set_title("M√©tricas de Desempenho (5 √âpocas)", fontsize=14, fontweight="bold")\n')
    f.write('ax.set_ylim([0, 1])\n')
    f.write('ax.legend(fontsize=10)\n')
    f.write('ax.grid(True, alpha=0.3)\n')
    f.write('plt.tight_layout()\n')
    f.write('plt.savefig("./graphs/metrics_curve.png", dpi=300, bbox_inches="tight")\n')
    f.write('plt.show()\n')
    f.write('print("‚úÖ Gr√°fico exibido e salvo: ./graphs/metrics_curve.png")\n\n')

    f.write('# GR√ÅFICO 4: Matriz de Confus√£o\n')
    f.write('print("\\nüìä Gerando matriz de confus√£o...")\n')
    f.write('predictions = trainer.predict(tokenized_datasets["test"])\n')
    f.write('y_pred = np.argmax(predictions.predictions, axis=-1)\n')
    f.write('y_true = predictions.label_ids\n')
    f.write('cm = confusion_matrix(y_true, y_pred)\n\n')

    f.write('fig, ax = plt.subplots(figsize=(8, 6))\n')
    f.write('sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", cbar=True, \n')
    f.write('            xticklabels=["No Hate", "Hate"], \n')
    f.write('            yticklabels=["No Hate", "Hate"],\n')
    f.write('            annot_kws={"size": 16, "weight": "bold"})\n')
    f.write('ax.set_xlabel("Predi√ß√£o", fontsize=12, fontweight="bold")\n')
    f.write('ax.set_ylabel("Real", fontsize=12, fontweight="bold")\n')
    f.write('ax.set_title("Matriz de Confus√£o - Conjunto de Teste", fontsize=14, fontweight="bold")\n')
    f.write('plt.tight_layout()\n')
    f.write('plt.savefig("./graphs/confusion_matrix.png", dpi=300, bbox_inches="tight")\n')
    f.write('plt.show()\n')
    f.write('print("‚úÖ Gr√°fico exibido e salvo: ./graphs/confusion_matrix.png")\n\n')

    f.write('# GR√ÅFICO 5: Resumo final (dashboard)\n')
    f.write('fig = plt.figure(figsize=(16, 10))\n')
    f.write('gs = fig.add_gridspec(2, 2, hspace=0.3, wspace=0.3)\n\n')

    f.write('# Loss\n')
    f.write('ax1 = fig.add_subplot(gs[0, 0])\n')
    f.write('ax1.plot(epochs, eval_loss, marker="o", linewidth=2, markersize=6, color="red")\n')
    f.write('ax1.set_title("Loss", fontweight="bold")\n')
    f.write('ax1.set_xlabel("√âpoca")\n')
    f.write('ax1.set_ylabel("Loss")\n')
    f.write('ax1.grid(True, alpha=0.3)\n\n')

    f.write('# Accuracy\n')
    f.write('ax2 = fig.add_subplot(gs[0, 1])\n')
    f.write('ax2.plot(epochs, eval_accuracy, marker="o", linewidth=2, markersize=6, color="green")\n')
    f.write('ax2.set_title("Accuracy", fontweight="bold")\n')
    f.write('ax2.set_xlabel("√âpoca")\n')
    f.write('ax2.set_ylabel("Accuracy")\n')
    f.write('ax2.set_ylim([0, 1])\n')
    f.write('ax2.grid(True, alpha=0.3)\n\n')

    f.write('# F1, Precision, Recall\n')
    f.write('ax3 = fig.add_subplot(gs[1, 0])\n')
    f.write('ax3.plot(epochs, eval_f1, marker="o", linewidth=2, label="F1")\n')
    f.write('ax3.plot(epochs, eval_precision, marker="s", linewidth=2, label="Precision")\n')
    f.write('ax3.plot(epochs, eval_recall, marker="^", linewidth=2, label="Recall")\n')
    f.write('ax3.set_title("M√©tricas Detalhadas", fontweight="bold")\n')
    f.write('ax3.set_xlabel("√âpoca")\n')
    f.write('ax3.set_ylabel("Score")\n')
    f.write('ax3.set_ylim([0, 1])\n')
    f.write('ax3.legend()\n')
    f.write('ax3.grid(True, alpha=0.3)\n\n')

    f.write('# Confusion Matrix\n')
    f.write('ax4 = fig.add_subplot(gs[1, 1])\n')
    f.write('sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", cbar=False, ax=ax4,\n')
    f.write('            xticklabels=["No Hate", "Hate"], \n')
    f.write('            yticklabels=["No Hate", "Hate"])\n')
    f.write('ax4.set_title("Matriz de Confus√£o", fontweight="bold")\n')
    f.write('ax4.set_xlabel("Predi√ß√£o")\n')
    f.write('ax4.set_ylabel("Real")\n\n')

    f.write('plt.suptitle("Dashboard de Treinamento - HateBERT (5 √âpocas)", \n')
    f.write('             fontsize=16, fontweight="bold", y=0.995)\n')
    f.write('plt.savefig("./graphs/training_dashboard.png", dpi=300, bbox_inches="tight")\n')
    f.write('plt.show()\n')
    f.write('print("‚úÖ Gr√°fico exibido e salvo: ./graphs/training_dashboard.png")\n\n')

    f.write('# Salvar m√©tricas em JSON\n')
    f.write('metrics_summary = {\n')
    f.write('    "num_epochs": NUM_EPOCHS,\n')
    f.write('    "final_metrics": {\n')
    f.write('        "accuracy": float(test_results["eval_accuracy"]),\n')
    f.write('        "f1": float(test_results["eval_f1"]),\n')
    f.write('        "precision": float(test_results["eval_precision"]),\n')
    f.write('        "recall": float(test_results["eval_recall"])\n')
    f.write('    },\n')
    f.write('    "training_history": {\n')
    f.write('        "epochs": epochs,\n')
    f.write('        "eval_loss": eval_loss,\n')
    f.write('        "eval_accuracy": eval_accuracy,\n')
    f.write('        "eval_f1": eval_f1,\n')
    f.write('        "eval_precision": eval_precision,\n')
    f.write('        "eval_recall": eval_recall\n')
    f.write('    }\n')
    f.write('}\n\n')

    f.write('with open("./graphs/metrics_summary.json", "w") as f:\n')
    f.write('    json.dump(metrics_summary, f, indent=2)\n')
    f.write('print("‚úÖ M√©tricas salvas: ./graphs/metrics_summary.json")\n\n')

    f.write('print("\\n" + "="*60)\n')
    f.write('print("‚úÖ TREINAMENTO CONCLU√çDO!")\n')
    f.write('print("="*60)\n')
    f.write('print(f"üìÅ Modelo salvo em: {OUTPUT_DIR}")\n')
    f.write('print(f"üìä Gr√°ficos salvos em: ./graphs/")\n')
    f.write('print("\\nüìà Gr√°ficos gerados:")\n')
    f.write('print("   ‚Ä¢ loss_curve.png - Curva de perda")\n')
    f.write('print("   ‚Ä¢ accuracy_curve.png - Curva de acur√°cia")\n')
    f.write('print("   ‚Ä¢ metrics_curve.png - F1, Precision e Recall")\n')
    f.write('print("   ‚Ä¢ confusion_matrix.png - Matriz de confus√£o")\n')
    f.write('print("   ‚Ä¢ training_dashboard.png - Dashboard completo")\n')
    f.write('print("   ‚Ä¢ metrics_summary.json - Resumo das m√©tricas")\n')
    f.write('print("="*60)\n')

print("‚úÖ Script criado: train_5epochs_graphs.py")
print("\nüöÄ Iniciando treinamento com 5 √©pocas...")
print("‚è±Ô∏è Tempo estimado com GPU: ~12-20 minutos")
print("üìä Gr√°ficos ser√£o gerados automaticamente ao final")
print("=" * 60)

!python train_5epochs_graphs.py

# ========================================
# SALVAR APENAS OS GR√ÅFICOS NO GOOGLE DRIVE
# ========================================

print("üì§ Conectando ao Google Drive...")
from google.colab import drive
drive.mount('/content/drive')

print("\nüìÅ Criando pasta no Drive para os gr√°ficos...")
import os
import shutil
from datetime import datetime

# Criar pasta com data atual
data_atual = datetime.now().strftime("%Y-%m-%d")
drive_folder = f"/content/drive/MyDrive/HateBERT_Graphs_{data_atual}"

# Criar pasta se n√£o existir
os.makedirs(drive_folder, exist_ok=True)
print(f"üìÇ Pasta: {drive_folder}")

# Caminho dos gr√°ficos gerados
graphics_source = "/content/HateBERT_Project/osfstorage/graphs"

# Verificar se os gr√°ficos existem
if os.path.exists(graphics_source):
    print(f"\nüìä Encontrei {len(os.listdir(graphics_source))} arquivos na pasta de gr√°ficos:")

    # Listar todos os arquivos de gr√°ficos
    graphics_files = os.listdir(graphics_source)

    # Copiar cada arquivo de gr√°fico
    for file in graphics_files:
        if file.endswith(('.png', '.jpg', '.jpeg', '.json')):
            source_file = os.path.join(graphics_source, file)
            dest_file = os.path.join(drive_folder, file)

            shutil.copy2(source_file, dest_file)
            print(f"‚úÖ Copiado: {file}")

    print(f"\nüéØ Total de {len([f for f in graphics_files if f.endswith('.png')])} gr√°ficos PNG salvos")
    print(f"üìà Total de {len([f for f in graphics_files if f.endswith('.json')])} arquivos JSON salvos")

else:
    print(f"‚ùå Pasta de gr√°ficos n√£o encontrada: {graphics_source}")
    print("Execute o treinamento primeiro para gerar os gr√°ficos!")

# Mostrar o que foi salvo
print("\nüìã Gr√°ficos salvos no Drive:")
if os.path.exists(drive_folder):
    for file in os.listdir(drive_folder):
        if file.endswith('.png'):
            print(f"   üìä {file}")

print("\n‚úÖ PRONTO! Gr√°ficos salvos no Google Drive.")